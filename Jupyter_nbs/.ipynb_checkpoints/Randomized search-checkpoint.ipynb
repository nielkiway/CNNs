{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['/media/jan/Volume_big/datasets/Second_try/Grid_size_874_binary/3layer/no_porosity',\n",
    "        '/media/jan/Volume_big/datasets/Second_try/Grid_size_874_binary/3layer/porosity']\n",
    "\n",
    "length = 2000\n",
    "image_paths = []\n",
    "labels = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 128\n",
    "width = 128\n",
    "depth = 3\n",
    "inputShape = (height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dirs: \n",
    "    cur_paths = []\n",
    "    for path in os.listdir(d):\n",
    "        full_path = os.path.join(d,path)\n",
    "        cur_paths.append(full_path)\n",
    "        \n",
    "    random.seed(42)\n",
    "    random.shuffle(cur_paths)\n",
    "    cur_paths = cur_paths[:length]\n",
    "    \n",
    "    image_paths.append(cur_paths)        \n",
    "\n",
    "image_paths = [val for sublist in image_paths for val in sublist]\n",
    "random.seed(42)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "######\n",
    "for path in image_paths:\n",
    "    label = path.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    \n",
    "    array = np.load(path)\n",
    "    img = Image.fromarray(array)\n",
    "    img = img.resize((height, width), PIL.Image.LANCZOS)\n",
    "    array_resized_flattened = np.array(img)\n",
    "    data.append(array_resized_flattened)\n",
    "    \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "trainY = np.hstack((trainY, 1- trainY))\n",
    "\n",
    "testY = lb.transform(testY)\n",
    "testY = np.hstack((testY, 1- testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr = 0.001):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(3,(6,6), padding=\"same\", input_shape = inputShape))   #, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = -1))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(6, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    \n",
    "    optimizer = Adam(lr = lr)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [8, 16, 32]\n",
    "epochs = [10,15,20]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [8, 16, 32], 'epochs': [10, 15, 20], 'lr': [0.001, 0.01, 0.1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter = 2,n_jobs=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6461 - acc: 0.6690\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 786us/step - loss: 0.5675 - acc: 0.6972\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 787us/step - loss: 0.5509 - acc: 0.7067\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 781us/step - loss: 0.5528 - acc: 0.7010\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 793us/step - loss: 0.5550 - acc: 0.6985\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 794us/step - loss: 0.5438 - acc: 0.7075\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 789us/step - loss: 0.5421 - acc: 0.7045\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 804us/step - loss: 0.5361 - acc: 0.7193\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 0.5320 - acc: 0.7262\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 788us/step - loss: 0.5956 - acc: 0.6697\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 796us/step - loss: 0.5797 - acc: 0.6920\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 792us/step - loss: 0.5520 - acc: 0.7055\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 800us/step - loss: 0.5463 - acc: 0.7117\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 792us/step - loss: 0.5366 - acc: 0.7090\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 796us/step - loss: 0.5342 - acc: 0.7083\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 795us/step - loss: 0.5440 - acc: 0.7157\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 0.5308 - acc: 0.7208\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 797us/step - loss: 0.5293 - acc: 0.7097\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 788us/step - loss: 0.5092 - acc: 0.7315\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 787us/step - loss: 0.5224 - acc: 0.7255\n",
      "1000/1000 [==============================] - 0s 434us/step\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.6448 - acc: 0.6470\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 802us/step - loss: 0.5681 - acc: 0.6820\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 804us/step - loss: 0.5556 - acc: 0.6957\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 801us/step - loss: 0.5537 - acc: 0.7017\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 805us/step - loss: 0.5512 - acc: 0.6882\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 818us/step - loss: 0.5404 - acc: 0.7140\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 815us/step - loss: 0.5417 - acc: 0.6967\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 785us/step - loss: 0.5403 - acc: 0.7040\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 0.5378 - acc: 0.6942\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 786us/step - loss: 0.5331 - acc: 0.7152\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 785us/step - loss: 0.5391 - acc: 0.6970\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 826us/step - loss: 0.5338 - acc: 0.7163\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 808us/step - loss: 0.5378 - acc: 0.6997\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 787us/step - loss: 0.5334 - acc: 0.7122\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 798us/step - loss: 0.5289 - acc: 0.7110\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 0.5402 - acc: 0.6990\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 0.5339 - acc: 0.7147\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 793us/step - loss: 0.5243 - acc: 0.7182\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 798us/step - loss: 0.5288 - acc: 0.7065\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 800us/step - loss: 0.5292 - acc: 0.7055\n",
      "1000/1000 [==============================] - 0s 470us/step\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.6211 - acc: 0.6750\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 804us/step - loss: 0.5648 - acc: 0.6935\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 819us/step - loss: 0.5502 - acc: 0.7087\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 812us/step - loss: 0.5473 - acc: 0.6987\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 805us/step - loss: 0.5432 - acc: 0.7025\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 807us/step - loss: 0.5402 - acc: 0.7122\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 812us/step - loss: 0.5272 - acc: 0.7103\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 802us/step - loss: 0.5290 - acc: 0.7190\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 802us/step - loss: 0.5351 - acc: 0.7185\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 811us/step - loss: 0.5213 - acc: 0.7240\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 794us/step - loss: 0.5183 - acc: 0.7230\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 801us/step - loss: 0.5276 - acc: 0.7225\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 809us/step - loss: 0.5162 - acc: 0.7310\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 811us/step - loss: 0.5241 - acc: 0.7208\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 823us/step - loss: 0.5240 - acc: 0.7205\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 807us/step - loss: 0.5246 - acc: 0.7232\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 783us/step - loss: 0.5241 - acc: 0.7125\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 810us/step - loss: 0.5060 - acc: 0.7200\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 810us/step - loss: 0.5150 - acc: 0.7248\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 817us/step - loss: 0.5172 - acc: 0.7100\n",
      "1000/1000 [==============================] - 1s 541us/step\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6586 - acc: 0.6512\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.6035 - acc: 0.6890\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5837 - acc: 0.6850\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5672 - acc: 0.6985\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5976 - acc: 0.6845\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5575 - acc: 0.7080\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5559 - acc: 0.7132\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5470 - acc: 0.7147\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5502 - acc: 0.7082\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5444 - acc: 0.7107\n",
      "1000/1000 [==============================] - 1s 713us/step\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6611 - acc: 0.6408\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.6096 - acc: 0.6705\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5825 - acc: 0.6890\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5741 - acc: 0.6930\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5821 - acc: 0.6848\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5666 - acc: 0.6980\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5573 - acc: 0.7030\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5604 - acc: 0.6997\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5603 - acc: 0.6952\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5586 - acc: 0.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 753us/step\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6838 - acc: 0.6260\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.6033 - acc: 0.6945\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5707 - acc: 0.7027\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5557 - acc: 0.7063\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5630 - acc: 0.7007\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5514 - acc: 0.7115\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5353 - acc: 0.7087\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5366 - acc: 0.7200\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5487 - acc: 0.7085\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5381 - acc: 0.7223\n",
      "1000/1000 [==============================] - 1s 832us/step\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 6s 2ms/step - loss: 0.6603 - acc: 0.6418\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5826 - acc: 0.6917\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5768 - acc: 0.6902\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5623 - acc: 0.7005\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5513 - acc: 0.7055\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5504 - acc: 0.7093\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5603 - acc: 0.7023\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5557 - acc: 0.7002\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5590 - acc: 0.6933\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5475 - acc: 0.7105\n"
     ]
    }
   ],
   "source": [
    "random_result = random.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([34.58499773, 31.02299913]),\n",
       " 'std_fit_time': array([0.61409201, 0.11164177]),\n",
       " 'mean_score_time': array([0.48491605, 0.76929331]),\n",
       " 'std_score_time': array([0.04478946, 0.04992632]),\n",
       " 'param_lr': masked_array(data=[0.01, 0.001],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[20, 10],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[16, 8],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'lr': 0.01, 'epochs': 20, 'batch_size': 16},\n",
       "  {'lr': 0.001, 'epochs': 10, 'batch_size': 8}],\n",
       " 'split0_test_score': array([0.69  , 0.7035]),\n",
       " 'split1_test_score': array([0.726, 0.696]),\n",
       " 'split2_test_score': array([0.6705, 0.694 ]),\n",
       " 'mean_test_score': array([0.6955    , 0.69783333]),\n",
       " 'std_test_score': array([0.02298913, 0.00408928]),\n",
       " 'rank_test_score': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.697833 using {'lr': 0.001, 'epochs': 10, 'batch_size': 8}\n",
      "0.695500 (0.022989) with: {'lr': 0.01, 'epochs': 20, 'batch_size': 16}\n",
      "0.697833 (0.004089) with: {'lr': 0.001, 'epochs': 10, 'batch_size': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "means = random_result.cv_results_['mean_test_score']\n",
    "stds = random_result.cv_results_['std_test_score']\n",
    "params = random_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
